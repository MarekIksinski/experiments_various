

main app:
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Aug 8 10:30:00 2025
Updated on Sun Aug 10 01:00:00 2025
Updated on Mon Aug 11 09:00:00 2025
Updated on Thu Aug 14 16:00:00 2025
Updated on Tue Sep 30 00:15:00 2025

@author: marek (w/ Gemini)

This module defines the second version of the coding agent. It is a more
advanced, self-correcting tool that not only generates code but also
generates and runs unit tests to ensure correctness. It can now be run
interactively from the CLI and can auto-generate test plans.
"""
import requests
import json
import traceback
import re
import os
import shutil
import sys # Needed for interactive multi-line input
from typing import Dict, Any, Optional

from project_manager import ProjectManager
from conversation_manager import ConversationManager

# --- Configuration for this specific tool ---
CODING_AGENT_CONFIG = {
    "OLLAMA_API_URL": "http://192.168.1.127:11434/api/chat",
    "OUTPUT_DIR": "generated_code",
    "MODELS": {
        "coder": {"name": "qwen3-coder:latest", "options": {"temperature": 0.6, "num_ctx": 16000, "top_p": 0.95}},
        "tester": {"name": "qwen3-coder:latest", "options": {"temperature": 0.1, "num_ctx": 16000, "top_p": 0.8}},
        "debugger": {"name": "qwen3-coder:latest", "options": {"temperature": 0.1, "num_ctx": 16000, "top_p": 0.95}},
        "analyzer": {"name": "qwen3-coder:latest", "options": {"temperature": 0.0, "num_ctx": 16000}},
        # --- NEW: Model for generating the test plan from the prompt ---
        "planner": {"name": "qwen3-coder:latest", "options": {"temperature": 0.2, "num_ctx": 16000, "top_p": 0.8}}
    }
}
MAX_DEBUG_ATTEMPTS = 3
MAX_TEST_REGEN_ATTEMPTS = 2

class CodingAgentV2:
    """
    A self-correcting coding agent that generates, tests, and debugs code.
    """
    def __init__(self, conversation_manager: ConversationManager):
        self.manager = conversation_manager
        self.project_manager = ProjectManager(base_dir="temp_coding_project")
        os.makedirs(CODING_AGENT_CONFIG["OUTPUT_DIR"], exist_ok=True)

    def _call_ollama_api(self, messages: list, model_key: str) -> str:
        """Internal helper to send requests to the Ollama API."""
        model_config = CODING_AGENT_CONFIG["MODELS"].get(model_key)
        if not model_config:
            raise ValueError(f"Model key '{model_key}' not found in config.")

        try:
            payload = {
                "model": model_config["name"],
                "messages": messages,
                "options": model_config["options"],
                "stream": False
            }
            # Setting timeout to None for potentially long-running generation tasks
            response = requests.post(CODING_AGENT_CONFIG["OLLAMA_API_URL"], json=payload, timeout=None)
            response.raise_for_status()
            return response.json().get("message", {}).get("content", "").strip()
        except requests.exceptions.RequestException as e:
            print(f"Coding Agent API Error: {e}")
            return f"Error: Failed to connect to '{model_config['name']}' API. Details: {e}"

    # --- NEW: Method to auto-generate a test plan ---
    def _generate_test_plan(self, language: str, code_prompt: str) -> str:
        """Uses an LLM to generate a test plan based on the code prompt."""
        print("  -> [CodingAgentV2] Generating test plan from prompt...")
        prompt = f"""
        You are an expert Quality Assurance (QA) engineer. Your task is to create a detailed, step-by-step test plan for a piece of code that will be written in {language}.
        Analyze the following user request and break it down into a numbered list of specific test cases.

        == User Code Request ==
        {code_prompt}

        == Instructions ==
        1.  Identify the core functionalities described in the request.
        2.  For each functionality, define at least one "happy path" test case (i.e., it works with normal, expected inputs).
        3.  Identify and create test cases for edge conditions (e.g., empty inputs, zero, large numbers, empty strings).
        4.  Identify and create test cases for error conditions (e.g., invalid input types, division by zero).
        5.  Format your output as a clean, numbered list. Do not include any explanations, conversational text, or markdown.
        
        Example Output:
        1. Test the add function with two positive integers.
        2. Test the add function with a positive and a negative integer.
        3. Test the divide function with a non-zero denominator.
        4. Test that the divide function raises a ValueError when the denominator is zero.
        """
        messages = [{'role': 'user', 'content': prompt}]
        generated_plan = self._call_ollama_api(messages, "planner")
        return generated_plan

    def _generate_code(self, language: str, prompt: str, initial_code: Optional[str] = None, mode: str = 'generate') -> str:
        """Generates a code snippet based on a natural language prompt."""
        print(f"  -> [CodingAgentV2] Generating {language} code in {mode} mode...")
        system_prompt = f"""You are an expert {language} programmer. Your task is to write a single, clean, well-commented, and efficient code snippet that fulfills the user's request.
        Respond with ONLY the code snippet, enclosed in a single markdown code block. Do not include any explanations or conversational text outside the code block."""
        
        user_message = prompt
        if initial_code:
            if mode == 'refactor':
                user_message = f"Please improve this existing code based on the following prompt:\n\n== Existing Code ==\n```python\n{initial_code}\n```\n\n== Improvement Prompt ==\n{prompt}"
            elif mode == 'debug':
                user_message = f"Please debug and fix this existing code based on the following prompt and a test plan that will be provided:\n\n== Existing Code ==\n```python\n{initial_code}\n```\n\n== Debugging Prompt ==\n{prompt}"
        
        messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': user_message}]
        raw_code = self._call_ollama_api(messages, "coder")
        cleaned_code = re.sub(r'```python|```', '', raw_code).strip()
        return cleaned_code

    def _generate_unit_tests(self, file_name: str, code_content: str, test_plan_description: str) -> str:
        """Generates pytest unit tests based on the provided code content and test plan."""
        print("  -> [CodingAgentV2] Generating unit tests...")
        prompt = f"""
        You are an expert Python unit test developer. Your task is to write pytest unit tests for the provided Python code, strictly following the test plan.

        == Original Python File Name ==
        {file_name}

        == Generated Python Code ==
        ```python
        {code_content}
        ```

        == Test Plan ==
        {test_plan_description}

        == Instructions ==
        1.  Write valid `pytest` test functions. Name the test file `test_{file_name.replace('.py', '')}.py`.
        2.  Import the necessary classes/functions from the original file.
        3.  Implement test cases that cover all aspects mentioned in the `Test Plan`.
        4.  For negative test cases (e.g., expected errors), use `pytest.raises`.
        5.  Use assertions (`assert`) to verify expected behavior.
        6.  Return ONLY the Python code for the unit tests. Do NOT include any explanations or markdown fences.
        """
        raw_test_code = self._call_ollama_api([{'role': 'user', 'content': prompt}], "tester")
        cleaned_test_code = re.sub(r'```python|```', '', raw_test_code).strip()
        return cleaned_test_code

    def _debug_code(self, code_content: str, test_output: str, test_file: str) -> str:
        """Uses an LLM to debug and fix code based on test output."""
        print("  -> [CodingAgentV2] Debugging failed code...")
        prompt = f"""
        You are a senior software engineer. The following code snippet failed to pass its unit tests.
        Your task is to analyze the code and the test failure output, identify the bug, and provide a corrected version of the code.

        == Original Code ==
        ```python
        {code_content}
        ```

        == Test Failure Output (from {test_file}) ==
        ```
        {test_output}
        ```

        == Instructions ==
        1.  Carefully examine the code and the test output to find the root cause of the error.
        2.  Provide a corrected version of the ENTIRE code snippet.
        3.  Return ONLY the corrected Python code, enclosed in a single markdown code block.
        """
        messages = [{'role': 'user', 'content': prompt}]
        raw_fixed_code = self._call_ollama_api(messages, "debugger")
        cleaned_fixed_code = re.sub(r'```python|```', '', raw_fixed_code).strip()
        return cleaned_fixed_code
    
    def _analyze_test_failure(self, code_content: str, test_output: str) -> str:
        """Analyzes a test failure to determine if the bug is in the code or the test."""
        print("  -> [CodingAgentV2] Analyzing test failure with analyzer model...")
        prompt = f"""
        You are a quality assurance expert. Analyze the provided Python code and the output from a failed test run.
        Your task is to determine the most likely cause of the failure.

        == Code ==
        ```python
        {code_content}
        ```

        == Test Failure Output ==
        ```
        {test_output}
        ```

        Based on your analysis, state whether the failure is a result of a bug in the code or a flaw in the unit test itself.
        Respond with ONLY one of the following keywords: 'code_bug', 'test_bug', or 'cannot_determine'.
        """
        messages = [{'role': 'user', 'content': prompt}]
        analysis_result = self._call_ollama_api(messages, "analyzer").strip().lower()
        if analysis_result not in ['code_bug', 'test_bug']:
            return 'cannot_determine'
        return analysis_result

    def execute_coding_agent_v2(self, conversation_id: int, language: str, code_file: str, prompt: str, test_plan: str, mode: str = 'generate', initial_code: Optional[str] = None) -> str:
        """Orchestrates the entire code generation, testing, and debugging process."""
        final_answer = "An error occurred during the coding process."
        test_passed = False
        
        try:
            self.project_manager.create_project()
            
            if initial_code and mode in ['refactor', 'debug']:
                generated_code = self._generate_code(language, prompt, initial_code, mode)
            else:
                generated_code = self._generate_code(language, prompt)
            
            self.project_manager.write_file(code_file, generated_code)
            
            test_file = f"test_{code_file}"
            test_output = ""
            analysis_result = 'code_bug' # Default assumption
            
            for attempt in range(MAX_DEBUG_ATTEMPTS + MAX_TEST_REGEN_ATTEMPTS):
                print(f"  -> [CodingAgentV2] Starting test attempt {attempt + 1}...")
                generated_tests = self._generate_unit_tests(code_file, generated_code, test_plan)
                self.project_manager.write_file(test_file, generated_tests)
                
                stdout, stderr, returncode = self.project_manager.run_command(['pytest', '-q', '--tb=no', test_file])
                
                if returncode == 0:
                    print(f"  -> [CodingAgentV2] Tests passed successfully on attempt {attempt + 1}.")
                    test_output = stdout
                    test_passed = True
                    self.manager.save_successful_code(conversation_id, code_file, prompt, generated_code, test_plan)
                    break
                else:
                    print(f"  -> [CodingAgentV2] Tests failed on attempt {attempt + 1}. Analyzing failure...")
                    test_output = stdout + stderr
                    
                    analysis_result = self._analyze_test_failure(generated_code, test_output)
                    print(f"  -> [CodingAgentV2] Analysis result: '{analysis_result}'")
                    
                    if analysis_result == 'code_bug' and attempt < MAX_DEBUG_ATTEMPTS:
                        print("  -> [CodingAgentV2] Identified as a code bug. Attempting to debug...")
                        generated_code = self._debug_code(generated_code, test_output, test_file)
                        self.project_manager.write_file(code_file, generated_code)
                    elif analysis_result == 'test_bug' and attempt < MAX_TEST_REGEN_ATTEMPTS:
                        print("  -> [CodingAgentV2] Identified as a test bug. Regenerating tests...")
                        pass # Loop will regenerate tests
                    else:
                        print("  -> [CodingAgentV2] Cannot determine cause or max attempts reached. Stopping.")
                        break

            final_file_path = os.path.join(CODING_AGENT_CONFIG["OUTPUT_DIR"], code_file)
            print(f"\n  -> [CodingAgentV2] Saving final code to '{final_file_path}'...")
            shutil.copy(os.path.join(self.project_manager.current_dir, code_file), final_file_path)

            if test_passed:
                final_answer = (f"I have successfully generated and tested the code. All tests passed.\n"
                                f"The final code has been saved to `{final_file_path}`.\n\n"
                                f"**Code:**\n```python\n{generated_code}\n```\n\n"
                                f"**Test Results:**\n```\n{test_output}\n```")
            else:
                analysis_message = "I was unable to fix a bug in the code within the allowed attempts." if analysis_result == 'code_bug' else "My analysis suggests the failure may be due to a flaw in the generated tests, not the code itself."
                final_answer = (f"I was unable to produce a working solution that passes all tests.\n"
                                f"The last code version has been saved to `{final_file_path}`.\n\n"
                                f"{analysis_message}\n\n"
                                f"**Last Code Attempt:**\n```python\n{generated_code}\n```\n\n"
                                f"**Final Test Output:**\n```\n{test_output}\n```")
                self.manager.save_failed_code(conversation_id, code_file, prompt, generated_code, test_plan, test_output)
                
        except Exception as e:
            final_answer = f"An unexpected error occurred during coding agent execution: {e}\n{traceback.format_exc()}"
        finally:
            self.project_manager.cleanup()
        
        return final_answer

# --- UPDATED: Interactive main function with auto-test plan generation ---

def _get_multiline_input(prompt_message: str) -> str:
    """Helper function to get multi-line input from the user."""
    print(f"\n{prompt_message}")
    print(" (Enter your text. Press Ctrl-D on Linux/macOS or Ctrl-Z+Enter on Windows when done)")
    lines = sys.stdin.readlines()
    return "".join(lines).strip()

def main():
    """The main function to run the agent in an interactive CLI mode."""
    print("--- Coding Agent V2: Interactive Mode ---")
    print("Please provide the following details for your coding task.")
    
    try:
        language = input("\n▶ Enter the programming language (e.g., python): ")
        code_file = input("▶ Enter the target filename (e.g., my_module.py): ")
        prompt = _get_multiline_input("▶ Enter the main prompt describing the code:")

        # --- Setup managers early to use the agent's methods ---
        conv_manager = ConversationManager()
        coding_agent = CodingAgentV2(conv_manager)
        
        test_plan = ""
        while not test_plan:
            plan_choice = input("\n▶ Test Plan: [M]anual entry or [A]uto-generate? (M/a): ").lower().strip() or 'm'
            if plan_choice == 'a':
                generated_plan = coding_agent._generate_test_plan(language, prompt)
                print("\n--- Proposed Test Plan ---")
                print(generated_plan)
                print("--------------------------")
                confirm = input("▶ Use this plan? [Y/n] (or 'm' to enter manually): ").lower().strip() or 'y'
                if confirm == 'y':
                    test_plan = generated_plan
                elif confirm == 'n':
                    print("  (Generation cancelled.)")
                    continue # Re-ask the M/A choice
                else: # 'm' or anything else falls back to manual
                    test_plan = _get_multiline_input("▶ Enter your manual test plan:")
            else: # Manual entry
                test_plan = _get_multiline_input("▶ Enter your manual test plan:")

        mode = input("\n▶ Enter mode [generate, refactor, debug] (default: generate): ").lower().strip() or 'generate'
        if mode not in ['generate', 'refactor', 'debug']:
            print(f"  (Invalid mode '{mode}', defaulting to 'generate'.)")
            mode = 'generate'
        
        initial_code = None
        if mode in ['refactor', 'debug']:
            use_initial_file = input(f"▶ Do you want to provide an initial code file for '{mode}' mode? [y/N]: ").lower().strip()
            if use_initial_file == 'y':
                initial_code_file = input("  ▶ Enter the path to the initial code file: ")
                try:
                    with open(initial_code_file, 'r') as f:
                        initial_code = f.read()
                    print(f"--- Loaded initial code from '{initial_code_file}' ---")
                except FileNotFoundError:
                    print(f"FATAL: The initial code file '{initial_code_file}' was not found.")
                    return
        
        print("\n--- Initializing Agent and Starting Task ---")
        conv_id = conv_manager.start_new_conversation(name=f"Interactive CLI session for {code_file}")
        print(f"--- Started new conversation (ID: {conv_id}) ---")

        final_result = coding_agent.execute_coding_agent_v2(
            conversation_id=conv_id, language=language, code_file=code_file,
            prompt=prompt, test_plan=test_plan, mode=mode, initial_code=initial_code
        )

        print("\n" + "="*50)
        print("          AGENT EXECUTION COMPLETE")
        print("="*50 + "\n")
        print(final_result)

    except KeyboardInterrupt:
        print("\n\n--- Operation cancelled by user. Exiting. ---")
    except Exception as e:
        print(f"\n--- An unexpected error occurred: {e} ---")

if __name__ == "__main__":
    main()


project_manager script:

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Aug 8 10:00:00 2025

@author: marek (w/ Gemini)

This module provides a ProjectManager class that creates and manages an
isolated, temporary working directory. This is essential for safely
executing generated code and unit tests.
"""
import os
import shutil
import subprocess
from typing import Tuple, Any

class ProjectManager:
    """
    Manages a temporary project directory for writing and executing code.
    Ensures a clean, isolated environment for each task.
    """

    def __init__(self, base_dir: str = "temp_project"):
        self.base_dir = base_dir
        self.current_dir = None

    def create_project(self):
        """
        Creates a new, unique temporary directory for the project.
        Deletes any existing directory with the same name first.
        """
        print(f"ProjectManager: Creating new project directory at '{self.base_dir}'...")
        if os.path.exists(self.base_dir):
            shutil.rmtree(self.base_dir)
            print(f"ProjectManager: Removed old directory.")
        
        os.makedirs(self.base_dir)
        self.current_dir = self.base_dir
        print(f"ProjectManager: Directory created.")

    def write_file(self, file_name: str, content: str):
        """
        Writes content to a file within the current project directory.
        """
        if not self.current_dir:
            raise RuntimeError("No project directory exists. Call create_project() first.")
        
        file_path = os.path.join(self.current_dir, file_name)
        print(f"ProjectManager: Writing file '{file_name}'...")
        with open(file_path, "w") as f:
            f.write(content)

    def read_file(self, file_name: str) -> str:
        """
        Reads and returns the content of a file from the project directory.
        """
        if not self.current_dir:
            raise RuntimeError("No project directory exists. Call create_project() first.")
        
        file_path = os.path.join(self.current_dir, file_name)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_name}")

        with open(file_path, "r") as f:
            return f.read()

    def run_command(self, command: list[str], timeout: int = 60) -> Tuple[str, str, int]:
        """
        Runs a shell command within the project directory and captures its output.
        
        Args:
            command (list[str]): The command and its arguments.
            timeout (int): The maximum time to wait for the command to finish.

        Returns:
            A tuple containing (stdout, stderr, returncode).
        """
        if not self.current_dir:
            raise RuntimeError("No project directory exists. Call create_project() first.")

        print(f"ProjectManager: Executing command: {' '.join(command)}")
        try:
            result = subprocess.run(
                command,
                cwd=self.current_dir,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            return result.stdout, result.stderr, result.returncode
        except subprocess.TimeoutExpired:
            return "", "Error: Command timed out.", 1
        except Exception as e:
            return "", f"Error: Failed to execute command. Details: {e}", 1

    def cleanup(self):
        """
        Removes the entire project directory.
        """
        if self.base_dir and os.path.exists(self.base_dir):
            print(f"ProjectManager: Cleaning up project directory '{self.base_dir}'...")
            shutil.rmtree(self.base_dir)
            self.current_dir = None
            print("ProjectManager: Cleanup complete.")


if __name__ == '__main__':
    # --- Demo of ProjectManager ---
    print("--- ProjectManager Demo ---")
    pm = ProjectManager(base_dir="my_test_project")
    pm.create_project()
    
    # Write a simple Python file
    code_content = "print('Hello, world!')"
    pm.write_file("hello.py", code_content)
    
    # Run the file and capture output
    stdout, stderr, _ = pm.run_command(['python', 'hello.py'])
    print("\n--- Command Output ---")
    print(f"STDOUT: {stdout}")
    print(f"STDERR: {stderr}")
    
    # Cleanup
    pm.cleanup()
    print("\n--- Demo Finished ---")

conversation_manager script:

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Jun 8 15:50:00 2025
Updated on Sun Aug 10 01:00:00 2025

@author: marek (w/ Gemini)

This module provides a ConversationManager class to handle persistent storage
of conversations using SQLite (for text) and ChromaDB (for vectors).
It has now been updated to also store the state of the coding agent.
"""
import sqlite3
import os
import datetime
from typing import List, Dict, Optional

try:
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
except ImportError:
    print("FATAL: Langchain libraries not found. The ConversationManager cannot function.")
    exit(1)

class ConversationManager:
    """Manages the storage and retrieval of conversation history and coding agent data."""

    def __init__(self, base_dir: str = "Database", embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        print(f"--- Initializing Conversation Manager ---")
        os.makedirs(base_dir, exist_ok=True)
        self.sqlite_path = os.path.join(base_dir, "conversations.sqlite")
        self.chroma_path = os.path.join(base_dir, "conversation_vectors")

        try:
            self.embeddings = HuggingFaceEmbeddings(model_name=embedding_model, model_kwargs={'device': 'cpu'})
            self.db_conn = sqlite3.connect(self.sqlite_path)
            self.vector_store = Chroma(persist_directory=self.chroma_path, embedding_function=self.embeddings)
            self._create_sqlite_tables()
            print("--- Conversation Manager Initialized Successfully ---")
        except Exception as e:
            print(f"\n--- FATAL: Conversation Manager failed to initialize ---")
            raise e

    def _create_sqlite_tables(self):
        """Creates all necessary SQLite tables on initialization."""
        cursor = self.db_conn.cursor()
        
        # Original tables
        cursor.execute("CREATE TABLE IF NOT EXISTS conversations (id INTEGER PRIMARY KEY, start_time TEXT, name TEXT, session_summary TEXT);")
        cursor.execute("CREATE TABLE IF NOT EXISTS messages (id INTEGER PRIMARY KEY, conversation_id INTEGER, timestamp TEXT, role TEXT, content TEXT, FOREIGN KEY (conversation_id) REFERENCES conversations (id));")
        
        # --- NEW: Tables for the coding agent's history ---
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS code_solutions (
                id INTEGER PRIMARY KEY,
                conversation_id INTEGER,
                file_name TEXT NOT NULL,
                prompt TEXT NOT NULL,
                code_content TEXT NOT NULL,
                test_plan TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                FOREIGN KEY (conversation_id) REFERENCES conversations (id)
            );
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS code_failures (
                id INTEGER PRIMARY KEY,
                conversation_id INTEGER,
                file_name TEXT NOT NULL,
                prompt TEXT NOT NULL,
                code_content TEXT NOT NULL,
                test_plan TEXT NOT NULL,
                test_output TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                FOREIGN KEY (conversation_id) REFERENCES conversations (id)
            );
        """)
        
        self.db_conn.commit()

    def add_turn_to_history(self, conversation_id: int, user_content: str, assistant_content: str):
        """Adds a conversation turn to SQLite and ChromaDB."""
        try:
            cursor = self.db_conn.cursor()
            now = datetime.datetime.now().isoformat()
            cursor.execute("INSERT INTO messages (conversation_id, timestamp, role, content) VALUES (?, ?, ?, ?)", (conversation_id, now, 'user', user_content))
            user_message_id = cursor.lastrowid
            cursor.execute("INSERT INTO messages (conversation_id, timestamp, role, content) VALUES (?, ?, ?, ?)", (conversation_id, now, 'assistant', assistant_content))
            assistant_message_id = cursor.lastrowid
            
            combined_content = f"User: {user_content}\n\nAssistant: {assistant_content}"
            metadata = {"conversation_id": conversation_id, "user_message_id": user_message_id, "assistant_message_id": assistant_message_id, "timestamp": now}
            chroma_id = f"turn_{user_message_id}_{assistant_message_id}"
            
            self.vector_store.add_texts(texts=[combined_content], metadatas=[metadata], ids=[chroma_id])
            self.db_conn.commit()
            print(f"Successfully added turn (User: {user_message_id}, Assistant: {assistant_message_id}) to conversation {conversation_id}.")
        except Exception as e:
            print(f"Error adding turn to history: {e}")
            self.db_conn.rollback()
            
    def start_new_conversation(self, name: Optional[str] = None) -> int:
        """Starts a new conversation and returns its ID."""
        start_time = datetime.datetime.now().isoformat()
        cursor = self.db_conn.cursor()
        cursor.execute("INSERT INTO conversations (start_time, name) VALUES (?, ?)", (start_time, name))
        self.db_conn.commit()
        return cursor.lastrowid

    def list_conversations(self) -> List[Dict]:
        """Lists all existing conversations."""
        cursor = self.db_conn.cursor()
        cursor.execute("SELECT id, start_time, name, session_summary FROM conversations ORDER BY start_time DESC")
        rows = cursor.fetchall()
        return [{"id": r[0], "start_time": r[1], "name": r[2], "summary_exists": bool(r[3])} for r in rows]

    def update_conversation_summary(self, conversation_id: int, summary: str):
        """Updates the summary for a given conversation ID."""
        cursor = self.db_conn.cursor()
        cursor.execute("UPDATE conversations SET session_summary = ? WHERE id = ?", (summary, conversation_id))
        self.db_conn.commit()

    def get_conversation_summary(self, conversation_id: int) -> Optional[str]:
        """Retrieves the summary for a given conversation ID."""
        cursor = self.db_conn.cursor()
        cursor.execute("SELECT session_summary FROM conversations WHERE id = ?", (conversation_id,))
        result = cursor.fetchone()
        return result[0] if result and result[0] else None
        
    # --- NEW: Methods for the Coding Agent's code persistence ---
    def save_successful_code(self, conversation_id: int, file_name: str, prompt: str, code_content: str, test_plan: str):
        """Saves a successfully tested code solution to the database."""
        try:
            cursor = self.db_conn.cursor()
            now = datetime.datetime.now().isoformat()
            cursor.execute(
                "INSERT INTO code_solutions (conversation_id, file_name, prompt, code_content, test_plan, timestamp) VALUES (?, ?, ?, ?, ?, ?)",
                (conversation_id, file_name, prompt, code_content, test_plan, now)
            )
            self.db_conn.commit()
            print(f"Successfully saved a new code solution for file '{file_name}'.")
        except Exception as e:
            print(f"Error saving successful code: {e}")
            self.db_conn.rollback()

    def save_failed_code(self, conversation_id: int, file_name: str, prompt: str, code_content: str, test_plan: str, test_output: str):
        """Saves a failed code attempt to the database."""
        try:
            cursor = self.db_conn.cursor()
            now = datetime.datetime.now().isoformat()
            cursor.execute(
                "INSERT INTO code_failures (conversation_id, file_name, prompt, code_content, test_plan, test_output, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?)",
                (conversation_id, file_name, prompt, code_content, test_plan, test_output, now)
            )
            self.db_conn.commit()
            print(f"Successfully saved a new failed code attempt for file '{file_name}'.")
        except Exception as e:
            print(f"Error saving failed code: {e}")
            self.db_conn.rollback()
            
    def get_code_solution(self, file_name: str) -> Optional[Dict]:
        """Retrieves the most recent successful code solution for a given file name."""
        cursor = self.db_conn.cursor()
        cursor.execute(
            "SELECT id, conversation_id, file_name, prompt, code_content, test_plan, timestamp FROM code_solutions WHERE file_name = ? ORDER BY timestamp DESC LIMIT 1",
            (file_name,)
        )
        row = cursor.fetchone()
        if row:
            # Map the row to a dictionary for easier access
            return {
                "id": row[0],
                "conversation_id": row[1],
                "file_name": row[2],
                "prompt": row[3],
                "code_content": row[4],
                "test_plan": row[5],
                "timestamp": row[6]
            }
        return None

    def get_failed_attempts(self, file_name: str) -> List[Dict]:
        """Retrieves all failed code attempts for a given file name."""
        cursor = self.db_conn.cursor()
        cursor.execute(
            "SELECT id, conversation_id, file_name, prompt, code_content, test_plan, test_output, timestamp FROM code_failures WHERE file_name = ? ORDER BY timestamp DESC",
            (file_name,)
        )
        rows = cursor.fetchall()
        
        failures = []
        for row in rows:
            failures.append({
                "id": row[0],
                "conversation_id": row[1],
                "file_name": row[2],
                "prompt": row[3],
                "code_content": row[4],
                "test_plan": row[5],
                "test_output": row[6],
                "timestamp": row[7]
            })
        return failures

